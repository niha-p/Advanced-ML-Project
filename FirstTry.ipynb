{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder()\n",
      "[37 21 21 ..., 16 35 12]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "train=pd.read_csv('train.csv', parse_dates = ['Dates'])\n",
    "test=pd.read_csv('test.csv', parse_dates = ['Dates'])\n",
    "#Convert crime labels to numbers\n",
    "le_crime = preprocessing.LabelEncoder()\n",
    "\n",
    "crime = le_crime.fit_transform(train.Category)\n",
    "\n",
    " \n",
    "#Get binarized weekdays, districts, and hours.\n",
    "days = pd.get_dummies(train.DayOfWeek)\n",
    "district = pd.get_dummies(train.PdDistrict)\n",
    "hour = train.Dates.dt.hour\n",
    "hour = pd.get_dummies(hour) \n",
    " \n",
    "#Build new array\n",
    "train_data = pd.concat([hour, days, district], axis=1)\n",
    "train_data['crime']=crime\n",
    " \n",
    "#Repeat for test data\n",
    "days = pd.get_dummies(test.DayOfWeek)\n",
    "district = pd.get_dummies(test.PdDistrict)\n",
    " \n",
    "hour = test.Dates.dt.hour\n",
    "hour = pd.get_dummies(hour) \n",
    " \n",
    "test_data = pd.concat([hour, days, district], axis=1)\n",
    " \n",
    "\n",
    "features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
    "\t'Wednesday', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION',\n",
    "\t'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "features2 = [x for x in range(0,24)]\n",
    "features = features + features2\n",
    "\n",
    "training, validation = train_test_split(train_data, train_size=.60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LARCENY/THEFT', 'OTHER OFFENSES', 'NON-CRIMINAL', 'ASSAULT', 'DRUG/NARCOTIC', 'VEHICLE THEFT', 'VANDALISM', 'WARRANTS', 'BURGLARY', 'SUSPICIOUS OCC']\n",
      "OrderedDict([(16, 174900), (21, 126182), (20, 92304), (1, 76876), (7, 53971), (36, 53781), (35, 44725), (37, 42214), (4, 36755), (32, 31414)])\n"
     ]
    }
   ],
   "source": [
    "d=dict()\n",
    "from collections import OrderedDict\n",
    "for crime in train_data['crime']:\n",
    "    if crime in d:\n",
    "        d[crime]=d[crime]+1\n",
    "    else:\n",
    "        d[crime]=1\n",
    "        \n",
    "d_desc = OrderedDict(sorted(d.items(),key=lambda t: t[1], reverse=True)[:10])\n",
    "#newA = dict(sorted(d.iteritems(),key=lambda t: t[1], reverse=True)[:6])\n",
    "#print(newA)\n",
    "l=list(le_crime.inverse_transform(d_descending.keys()))\n",
    "print(l)\n",
    "print(d_desc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/strider/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 4 ..., 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "modelKMeans = KMeans(n_clusters=10, init='k-means++',n_init=10, max_iter=300,tol=0.0001)\n",
    "Z=modelKMeans.fit_predict(training[features])\n",
    "#predicted = np.array(modelBern.predict_proba(validation[features]))\n",
    "#print log_loss(validation['crime'], predicted)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday\n",
      "MISSION\n",
      "[  0.00000000e+00  -7.74755017e-02   1.95642151e-03  -7.14968941e-02\n",
      "   2.58756875e-02  -4.17820516e-02   4.77831770e-02   7.86662659e-01\n",
      "  -5.96196637e-01   1.27174090e+00  -0.00000000e+00  -4.66790607e-01\n",
      "   2.27550825e-01   6.88956772e-01  -6.12623331e-01   8.49332861e-01\n",
      "  -2.03803998e+00  -2.05548092e-01  -2.28191033e-01  -2.12696242e-01\n",
      "   2.52923522e-01   3.28693277e-01   4.85771242e-01   5.30255839e-01\n",
      "   5.48417900e-01  -1.16841564e-01   1.26071638e-05  -2.56174788e-01\n",
      "  -5.06033103e-01  -5.16232998e-01  -4.95103301e-01  -4.76972452e-01\n",
      "  -3.92105766e-01  -8.29018473e-02  -1.18951727e-02   3.71431141e-01\n",
      "   2.86823308e-01   5.95908982e-01   8.71631118e-01   1.02573966e+00\n",
      "   7.91337369e-01]\n",
      "19.3939700139\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.Lasso(alpha=0.0001)\n",
    "clf.fit(training[features], training['crime'])\n",
    "l=clf.coef_\n",
    "for i in range(0,len(l)):\n",
    "    if l[i]==0:\n",
    "        print(features[i])\n",
    "\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "\n",
    "X = training[features]\n",
    "y = training['crime']\n",
    "\n",
    "estimators = {'k_means_crime_10': KMeans(n_clusters=10,init='k-means++',n_init=10),\n",
    "              'k_means_crime_random_init': KMeans(n_clusters=10, n_init=10,\n",
    "                                              init='random')}\n",
    "\n",
    "\n",
    "fignum = 1\n",
    "for name, est in estimators.items():\n",
    "    fig = plt.figure(fignum, figsize=(6, 6))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "    plt.cla()\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "\n",
    "    ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(np.float))\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Petal width')\n",
    "    ax.set_ylabel('Sepal length')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    fignum = fignum + 1\n",
    "\n",
    "# Plot the ground truth\n",
    "fig = plt.figure(fignum, figsize=(4, 3))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "plt.cla()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(526829, 41)\n",
      "New X\n",
      "Sparsity with L1 penalty: 71.79%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf_l1_LR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-0b344966083d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0msparsity_l1_LR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_l1_LR\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sparsity with L1 penalty: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msparsity_l1_LR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score with L1 penalty: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mclf_l1_LR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_l1_LR' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.feature_selection import SelectFromModel\n",
    "X, y = training[features], training['crime']\n",
    "print(X.shape)\n",
    "modelLReg = LogisticRegression(C=.01, penalty='l1', tol=0.01).fit(training[features], training['crime'])\n",
    "#model = SelectFromModel(modelLReg, prefit=True)\n",
    "#X_new = modelLReg.transform(X)\n",
    "print(\"New X\")\n",
    "#print(X_new.shape)\n",
    "coef_l1_LR = modelLReg.coef_.ravel()\n",
    "sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity_l1_LR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599\n"
     ]
    }
   ],
   "source": [
    "print(coef_l1_LR.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score with L1 penalty: 0.2229\n"
     ]
    }
   ],
   "source": [
    "print(\"score with L1 penalty: %.4f\" % modelLReg.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 41)\n"
     ]
    }
   ],
   "source": [
    "print(modelLReg.coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(526829, 41)\n",
      "New X\n",
      "(526829, 19)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float argument required, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-f19a12b6c46e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New X\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sparsity with L1 penalty: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: float argument required, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X, y = training[features], training['crime']\n",
    "print(X.shape)\n",
    "modelLReg = LogisticRegression()\n",
    "model = SelectFromModel(modelLReg)\n",
    "model.fit(training[features], training['crime'])\n",
    "X_new = model.transform(X)\n",
    "print(\"New X\")\n",
    "print(X_new.shape)\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % model.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 16, 17, 19,\n",
       "       20, 22])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
